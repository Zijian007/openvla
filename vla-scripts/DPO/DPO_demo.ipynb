{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45a55d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33d99cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-08-05 20:24:48.298157: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-05 20:24:48.298197: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-05 20:24:48.299869: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-05 20:24:48.309431: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-05 20:24:49.230375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">08/05 [20:25:08] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> | &gt;&gt; No private macro file found!                                            <a href=\"file:///home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/robosuite/macros.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">macros.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/robosuite/macros.py#53\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m08/05 [20:25:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m | >> No private macro file found!                                            \u001b]8;id=82431;file:///home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/robosuite/macros.py\u001b\\\u001b[2mmacros.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=724561;file:///home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/robosuite/macros.py#53\u001b\\\u001b[2m53\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> | &gt;&gt; It is recommended to use a private macro file                           <a href=\"file:///home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/robosuite/macros.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">macros.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/robosuite/macros.py#54\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">54</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m | >> It is recommended to use a private macro file                           \u001b]8;id=581400;file:///home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/robosuite/macros.py\u001b\\\u001b[2mmacros.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=678125;file:///home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/robosuite/macros.py#54\u001b\\\u001b[2m54\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> | &gt;&gt; To setup, run: python                                                   <a href=\"file:///home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/robosuite/macros.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">macros.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/robosuite/macros.py#55\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">55</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/robosu</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         <span style=\"color: #800080; text-decoration-color: #800080\">ite/scripts/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">setup_macros.py</span>                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m | >> To setup, run: python                                                   \u001b]8;id=336272;file:///home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/robosuite/macros.py\u001b\\\u001b[2mmacros.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=339637;file:///home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/robosuite/macros.py#55\u001b\\\u001b[2m55\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                 \u001b[0m         \u001b[35m/home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/robosu\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                 \u001b[0m         \u001b[35mite/scripts/\u001b[0m\u001b[95msetup_macros.py\u001b[0m                                                  \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt; No OpenGL_accelerate module loaded: No module named          <a href=\"file:///home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/OpenGL/acceleratesupport.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">acceleratesupport.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/OpenGL/acceleratesupport.py#24\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">24</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'OpenGL_accelerate'</span>                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >> No OpenGL_accelerate module loaded: No module named          \u001b]8;id=167932;file:///home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/OpenGL/acceleratesupport.py\u001b\\\u001b[2macceleratesupport.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=234435;file:///home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/OpenGL/acceleratesupport.py#24\u001b\\\u001b[2m24\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                 \u001b[0m         \u001b[32m'OpenGL_accelerate'\u001b[0m                                               \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import DPOConfig, DPOTrainer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from src.data_process import TrajectoryDataset\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional, Union\n",
    "import draccus\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from experiments.robot.robot_utils import get_model\n",
    "from libero.libero import benchmark\n",
    "import wandb\n",
    "from experiments.robot.libero.libero_utils import (\n",
    "    get_libero_dummy_action,\n",
    "    get_libero_env,\n",
    "    get_libero_image,\n",
    "    quat2axisangle,\n",
    "    save_rollout_video_CoA,\n",
    ")\n",
    "from experiments.robot.openvla_utils import get_processor, get_input\n",
    "from experiments.robot.robot_utils import (\n",
    "    DATE_TIME,\n",
    "    get_action,\n",
    "    get_CoA,\n",
    "    get_image_resize_size,\n",
    "    get_model,\n",
    "    invert_gripper_action,\n",
    "    normalize_gripper_action,\n",
    "    set_seed_everywhere,\n",
    ")\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "from torch.utils.data import Dataset, IterableDataset\n",
    "from transformers import PreTrainedTokenizerBase, BaseImageProcessor, FeatureExtractionMixin, ProcessorMixin\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b0723ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GenerateConfig:\n",
    "    # fmt: off\n",
    "\n",
    "    #################################################################################################################\n",
    "    # Model-specific parameters\n",
    "    #################################################################################################################\n",
    "    model_family: str = \"openvla\"                    # Model family\n",
    "    pretrained_checkpoint: Union[str, Path] = \"/mnt/sda/home/zijianwang/openvla/FT_res/openvla-7b-finetuned-libero-10+libero_10_no_noops+b4+lr-0.0005+lora-r48+dropout-0.0--image_aug--2025-07-18_19-26-25\"     # Pretrained checkpoint path\n",
    "    winner_trajectory_path: str = \"/mnt/sda/home/zijianwang/openvla/vla-scripts/DPO/winner_trajectory\"\n",
    "\n",
    "    #################################################################################################################\n",
    "    load_in_8bit: bool = False                       # (For OpenVLA only) Load with 8-bit quantization\n",
    "    load_in_4bit: bool = False                       # (For OpenVLA only) Load with 4-bit quantization\n",
    "\n",
    "    center_crop: bool = True                         # Center crop? (if trained w/ random crop image aug)\n",
    "\n",
    "    #################################################################################################################\n",
    "    # LIBERO environment-specific parameters\n",
    "    #################################################################################################################\n",
    "    task_suite_name: str = \"libero_10\"          # Task suite. Options: libero_spatial, libero_object, libero_goal, libero_10, libero_90\n",
    "    num_steps_wait: int = 10                         # Number of steps to wait for objects to stabilize in sim\n",
    "    num_trials_per_task: int = 50                    # Number of rollouts per task\n",
    "\n",
    "    #################################################################################################################\n",
    "    # Utils\n",
    "    #################################################################################################################\n",
    "    run_id_note: Optional[str] = None                # Extra note to add in run ID for logging\n",
    "    local_log_dir: str = \"./experiments/logs\"        # Local directory for eval logs\n",
    "\n",
    "    use_wandb: bool = False                          # Whether to also log results in Weights & Biases\n",
    "    wandb_project: str = \"YOUR_WANDB_PROJECT\"        # Name of W&B project to log to (use default!)\n",
    "    wandb_entity: str = \"YOUR_WANDB_ENTITY\"          # Name of entity to log under\n",
    "\n",
    "    seed: int = 7                                    # Random Seed (for reproducibility)\n",
    "\n",
    "    device: str = \"cuda:0\"\n",
    "\n",
    "    # fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "766f3fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model_and_config(cfg: GenerateConfig):\n",
    "    \"\"\"Setup and validate configuration, then load the model.\"\"\"\n",
    "    assert cfg.pretrained_checkpoint is not None, \"cfg.pretrained_checkpoint must not be None!\"\n",
    "    if \"image_aug\" in cfg.pretrained_checkpoint:\n",
    "        assert cfg.center_crop, \"Expecting `center_crop==True` because model was trained with image augmentations!\"\n",
    "    assert not (cfg.load_in_8bit and cfg.load_in_4bit), \"Cannot use both 8-bit and 4-bit quantization!\"\n",
    "\n",
    "    # Set random seed\n",
    "    set_seed_everywhere(cfg.seed)\n",
    "\n",
    "    cfg.unnorm_key = cfg.task_suite_name\n",
    "\n",
    "    # Load model\n",
    "    model = get_model(cfg)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def setup_logging_and_environment(cfg: GenerateConfig, model):\n",
    "    \"\"\"Setup logging and LIBERO environment.\"\"\"\n",
    "    # [OpenVLA] Check that the model contains the action un-normalization key\n",
    "    if cfg.model_family == \"openvla\":\n",
    "        # In some cases, the key must be manually modified (e.g. after training on a modified version of the dataset\n",
    "        # with the suffix \"_no_noops\" in the dataset name)\n",
    "        if cfg.unnorm_key not in model.norm_stats and f\"{cfg.unnorm_key}_no_noops\" in model.norm_stats:\n",
    "            cfg.unnorm_key = f\"{cfg.unnorm_key}_no_noops\"\n",
    "        assert cfg.unnorm_key in model.norm_stats, f\"Action un-norm key {cfg.unnorm_key} not found in VLA `norm_stats`!\"\n",
    "\n",
    "    # [OpenVLA] Get Hugging Face processor\n",
    "    processor = None\n",
    "    if cfg.model_family == \"openvla\":\n",
    "        processor = get_processor(cfg)\n",
    "\n",
    "    # Initialize local logging\n",
    "    run_id = f\"EVAL-{cfg.task_suite_name}-{cfg.model_family}-{DATE_TIME}\"\n",
    "    if cfg.run_id_note is not None:\n",
    "        run_id += f\"--{cfg.run_id_note}\"\n",
    "    os.makedirs(cfg.local_log_dir, exist_ok=True)\n",
    "    local_log_filepath = os.path.join(cfg.local_log_dir, run_id + \".txt\")\n",
    "    log_file = open(local_log_filepath, \"w\")\n",
    "    print(f\"Logging to local log file: {local_log_filepath}\")\n",
    "\n",
    "    # Initialize Weights & Biases logging as well\n",
    "    if cfg.use_wandb:\n",
    "        wandb.init(\n",
    "            entity=cfg.wandb_entity,\n",
    "            project=cfg.wandb_project,\n",
    "            name=run_id,\n",
    "        )\n",
    "\n",
    "    # Initialize LIBERO task suite\n",
    "    benchmark_dict = benchmark.get_benchmark_dict()\n",
    "    task_suite = benchmark_dict[cfg.task_suite_name]()\n",
    "    num_tasks_in_suite = task_suite.n_tasks\n",
    "    print(f\"Task suite: {cfg.task_suite_name}\")\n",
    "    log_file.write(f\"Task suite: {cfg.task_suite_name}\\n\")\n",
    "\n",
    "    # Get expected image dimensions\n",
    "    resize_size = get_image_resize_size(cfg)\n",
    "\n",
    "    return processor, log_file, task_suite, num_tasks_in_suite, resize_size, cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b42014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Starting OpenVLA LIBERO Inference Demo\n",
      "[*] Loading model and setting up configuration...\n",
      "[*] Instantiating Pretrained VLA model\n",
      "[*] Loading in BF16 with Flash-Attention Enabled\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">08/05 [20:17:33] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> | &gt;&gt; Expected `<span style=\"color: #808000; text-decoration-color: #808000\">transformers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.40</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>` and `<span style=\"color: #808000; text-decoration-color: #808000\">tokenizers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.19</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>`   <a href=\"file:///home/zijianwang/.cache/huggingface/modules/transformers_modules/openvla-7b-finetuned-libero-10+libero_10_no_noops+b4+lr-0.0005+lora-r48+dropout-0.0--image_aug--2025-07-18_19-26-25/modeling_prismatic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">modeling_prismatic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/zijianwang/.cache/huggingface/modules/transformers_modules/openvla-7b-finetuned-libero-10+libero_10_no_noops+b4+lr-0.0005+lora-r48+dropout-0.0--image_aug--2025-07-18_19-26-25/modeling_prismatic.py#228\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">228</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         but got `<span style=\"color: #808000; text-decoration-color: #808000\">transformers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.53</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>` and `<span style=\"color: #808000; text-decoration-color: #808000\">tokenizers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.21</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>`; there  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         might be inference-time regressions due to dependency changes.  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         If in doubt, pleaseuse the above versions.                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m08/05 [20:17:33]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m | >> Expected `\u001b[33mtransformers\u001b[0m==\u001b[1;36m4.40\u001b[0m.\u001b[1;36m1\u001b[0m` and `\u001b[33mtokenizers\u001b[0m==\u001b[1;36m0.19\u001b[0m.\u001b[1;36m1\u001b[0m`   \u001b]8;id=75954;file:///home/zijianwang/.cache/huggingface/modules/transformers_modules/openvla-7b-finetuned-libero-10+libero_10_no_noops+b4+lr-0.0005+lora-r48+dropout-0.0--image_aug--2025-07-18_19-26-25/modeling_prismatic.py\u001b\\\u001b[2mmodeling_prismatic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=861168;file:///home/zijianwang/.cache/huggingface/modules/transformers_modules/openvla-7b-finetuned-libero-10+libero_10_no_noops+b4+lr-0.0005+lora-r48+dropout-0.0--image_aug--2025-07-18_19-26-25/modeling_prismatic.py#228\u001b\\\u001b[2m228\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                 \u001b[0m         but got `\u001b[33mtransformers\u001b[0m==\u001b[1;36m4.53\u001b[0m.\u001b[1;36m3\u001b[0m` and `\u001b[33mtokenizers\u001b[0m==\u001b[1;36m0.21\u001b[0m.\u001b[1;36m2\u001b[0m`; there  \u001b[2m                         \u001b[0m\n",
       "\u001b[2;36m                 \u001b[0m         might be inference-time regressions due to dependency changes.  \u001b[2m                         \u001b[0m\n",
       "\u001b[2;36m                 \u001b[0m         If in doubt, pleaseuse the above versions.                      \u001b[2m                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 10.74it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 5.25 MiB is free. Process 574445 has 17.66 GiB memory in use. Including non-PyTorch memory, this process has 5.97 GiB memory in use. Of the allocated memory 5.55 GiB is allocated by PyTorch, and 40.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Setup model and configuration\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[*] Loading model and setting up configuration...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43msetup_model_and_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Setup logging and environment\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[*] Setting up logging and environment...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m, in \u001b[0;36msetup_model_and_config\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     11\u001b[0m cfg\u001b[38;5;241m.\u001b[39munnorm_key \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mtask_suite_name\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/mnt/sda/home/zijianwang/openvla/experiments/robot/robot_utils.py:44\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(cfg, wrap_diffusion_policy_for_droid)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load model for evaluation.\"\"\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mmodel_family \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenvla\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 44\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mget_vla\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected `model_family` found in config.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/sda/home/zijianwang/openvla/experiments/robot/openvla_utils.py:59\u001b[0m, in \u001b[0;36mget_vla\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Move model to device.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Note: `.to()` is not supported for 8-bit or 4-bit bitsandbytes models, but the model will\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m#       already be set to the right devices and casted to the correct dtype upon loading.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mload_in_8bit \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mload_in_4bit:\n\u001b[0;32m---> 59\u001b[0m     vla \u001b[38;5;241m=\u001b[39m \u001b[43mvla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Load dataset stats used during finetuning (for action un-normalization).\u001b[39;00m\n\u001b[1;32m     62\u001b[0m dataset_statistics_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cfg\u001b[38;5;241m.\u001b[39mpretrained_checkpoint, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_statistics.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/openvla/lib/python3.10/site-packages/transformers/modeling_utils.py:4110\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   4106\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4107\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4108\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4109\u001b[0m         )\n\u001b[0;32m-> 4110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/openvla/lib/python3.10/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/openvla/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/openvla/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 802 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/openvla/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/openvla/lib/python3.10/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/openvla/lib/python3.10/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 5.25 MiB is free. Process 574445 has 17.66 GiB memory in use. Including non-PyTorch memory, this process has 5.97 GiB memory in use. Of the allocated memory 5.55 GiB is allocated by PyTorch, and 40.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "\"\"\"Main function to run the OpenVLA LIBERO inference demo.\"\"\"\n",
    "print(\"[*] Starting OpenVLA LIBERO Inference Demo\")\n",
    "\n",
    "# Initialize configuration\n",
    "cfg = GenerateConfig()\n",
    "\n",
    "# Setup model and configuration\n",
    "print(\"[*] Loading model and setting up configuration...\")\n",
    "model = setup_model_and_config(cfg)\n",
    "\n",
    "# Setup logging and environment\n",
    "print(\"[*] Setting up logging and environment...\")\n",
    "processor, log_file, task_suite, num_tasks_in_suite, resize_size,cfg = setup_logging_and_environment(cfg, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99c3096e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Instantiating Pretrained VLA model\n",
      "[*] Loading in BF16 with Flash-Attention Enabled\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">08/05 [19:23:31] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> | &gt;&gt; Expected `<span style=\"color: #808000; text-decoration-color: #808000\">transformers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.40</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>` and `<span style=\"color: #808000; text-decoration-color: #808000\">tokenizers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.19</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>`   <a href=\"file:///home/zijianwang/.cache/huggingface/modules/transformers_modules/openvla-7b-finetuned-libero-10+libero_10_no_noops+b4+lr-0.0005+lora-r48+dropout-0.0--image_aug--2025-07-18_19-26-25/modeling_prismatic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">modeling_prismatic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/zijianwang/.cache/huggingface/modules/transformers_modules/openvla-7b-finetuned-libero-10+libero_10_no_noops+b4+lr-0.0005+lora-r48+dropout-0.0--image_aug--2025-07-18_19-26-25/modeling_prismatic.py#228\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">228</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         but got `<span style=\"color: #808000; text-decoration-color: #808000\">transformers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.53</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>` and `<span style=\"color: #808000; text-decoration-color: #808000\">tokenizers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.21</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>`; there  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         might be inference-time regressions due to dependency changes.  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         If in doubt, pleaseuse the above versions.                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m08/05 [19:23:31]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m | >> Expected `\u001b[33mtransformers\u001b[0m==\u001b[1;36m4.40\u001b[0m.\u001b[1;36m1\u001b[0m` and `\u001b[33mtokenizers\u001b[0m==\u001b[1;36m0.19\u001b[0m.\u001b[1;36m1\u001b[0m`   \u001b]8;id=60816;file:///home/zijianwang/.cache/huggingface/modules/transformers_modules/openvla-7b-finetuned-libero-10+libero_10_no_noops+b4+lr-0.0005+lora-r48+dropout-0.0--image_aug--2025-07-18_19-26-25/modeling_prismatic.py\u001b\\\u001b[2mmodeling_prismatic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=953893;file:///home/zijianwang/.cache/huggingface/modules/transformers_modules/openvla-7b-finetuned-libero-10+libero_10_no_noops+b4+lr-0.0005+lora-r48+dropout-0.0--image_aug--2025-07-18_19-26-25/modeling_prismatic.py#228\u001b\\\u001b[2m228\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                 \u001b[0m         but got `\u001b[33mtransformers\u001b[0m==\u001b[1;36m4.53\u001b[0m.\u001b[1;36m3\u001b[0m` and `\u001b[33mtokenizers\u001b[0m==\u001b[1;36m0.21\u001b[0m.\u001b[1;36m2\u001b[0m`; there  \u001b[2m                         \u001b[0m\n",
       "\u001b[2;36m                 \u001b[0m         might be inference-time regressions due to dependency changes.  \u001b[2m                         \u001b[0m\n",
       "\u001b[2;36m                 \u001b[0m         If in doubt, pleaseuse the above versions.                      \u001b[2m                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 10.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: <class 'transformers_modules.openvla-7b-finetuned-libero-10+libero_10_no_noops+b4+lr-0.0005+lora-r48+dropout-0.0--image_aug--2025-07-18_19-26-25.modeling_prismatic.OpenVLAForActionPrediction'>\n"
     ]
    }
   ],
   "source": [
    "ref_config = GenerateConfig(device = \"cuda:2\" )\n",
    "ref_model = get_model(ref_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710d916e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 212 success trajectories\n"
     ]
    }
   ],
   "source": [
    "# Create dataset instance\n",
    "dataset = TrajectoryDataset(cfg, cfg.winner_trajectory_path, cfg.task_suite_name, processor, device = cfg.device, model = model)\n",
    "\n",
    "# dataset只返回\"prompt_input_ids\": [1, 2, 3], \"chosen_input_ids\": [4, 5], \"rejected_input_ids\": [6], \n",
    "# attention_mask在DataCollatorForPreference生成, labels在dpotrainer.concatenated_forward中生成. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "997ab086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "dict_keys(['prompt_input_ids', 'chosen_input_ids', 'rejected_input_ids'])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset)):\n",
    "    print(dataset[i].keys())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eade6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, IterableDataset\n",
    "from transformers import PreTrainedTokenizerBase, BaseImageProcessor, FeatureExtractionMixin, ProcessorMixin\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "from typing import Union\n",
    "\n",
    "class CustomDPOTrainer(DPOTrainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def get_winner(self, batch: dict[str, Union[list, torch.LongTensor]]) -> dict:\n",
    "        pass\n",
    "    def get_loser(self, batch: dict[str, Union[list, torch.LongTensor]]) -> dict:\n",
    "        pass\n",
    "        \n",
    "    def _prepare_dataset(\n",
    "        self,\n",
    "        dataset: Union[Dataset, IterableDataset],\n",
    "        processing_class: Union[PreTrainedTokenizerBase, BaseImageProcessor, FeatureExtractionMixin, ProcessorMixin],\n",
    "        args: DPOConfig,\n",
    "        dataset_name: str,\n",
    "    ) -> Union[Dataset, IterableDataset]:  # return dataset, which will be used in _get_dataloader\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cd1f0f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute 'place_model_on_device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m DPOConfig(output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen2-0.5B-DPO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# print(training_args)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtraining_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplace_model_on_device\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \n",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute 'place_model_on_device'"
     ]
    }
   ],
   "source": [
    "training_args = DPOConfig(output_dir=\"Qwen2-0.5B-DPO\")\n",
    "# print(training_args)\n",
    "training_args.place_model_on_device = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffc1029c",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 5.25 MiB is free. Process 574445 has 17.66 GiB memory in use. Including non-PyTorch memory, this process has 5.97 GiB memory in use. Of the allocated memory 5.55 GiB is allocated by PyTorch, and 40.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mCustomDPOTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m, in \u001b[0;36mCustomDPOTrainer.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/openvla/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:441\u001b[0m, in \u001b[0;36mDPOTrainer.__init__\u001b[0;34m(self, model, ref_model, args, data_collator, train_dataset, eval_dataset, processing_class, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics, peft_config)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m         eval_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_dataset(eval_dataset, processing_class, args, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessing_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_cls_and_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_cls_and_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreprocess_logits_for_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess_logits_for_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# Gradient accumulation requires scaled loss. Normally, loss scaling in the parent class depends on whether the\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;66;03m# model accepts loss-related kwargs. Since we compute our own loss, this check is irrelevant. We set\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;66;03m# self.model_accepts_loss_kwargs to False to enable scaling.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_accepts_loss_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/openvla/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/openvla/lib/python3.10/site-packages/transformers/trainer.py:618\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# Bnb Quantized models doesn't support `.to` operation.\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_model_on_device\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mBITS_AND_BYTES\n\u001b[1;32m    617\u001b[0m ):\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_move_model_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_model_parallel:\n",
      "File \u001b[0;32m~/miniconda3/envs/openvla/lib/python3.10/site-packages/transformers/trainer.py:894\u001b[0m, in \u001b[0;36mTrainer._move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[0;32m--> 894\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mparallel_mode \u001b[38;5;241m==\u001b[39m ParallelMode\u001b[38;5;241m.\u001b[39mTPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtie_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/openvla/lib/python3.10/site-packages/transformers/modeling_utils.py:4110\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   4106\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4107\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4108\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4109\u001b[0m         )\n\u001b[0;32m-> 4110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/openvla/lib/python3.10/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/openvla/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/openvla/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 802 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/openvla/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/openvla/lib/python3.10/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/openvla/lib/python3.10/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 5.25 MiB is free. Process 574445 has 17.66 GiB memory in use. Including non-PyTorch memory, this process has 5.97 GiB memory in use. Of the allocated memory 5.55 GiB is allocated by PyTorch, and 40.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "trainer = CustomDPOTrainer(model=model, ref_model=ref_model, args=training_args, processing_class=processor, train_dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ac10a3",
   "metadata": {},
   "source": [
    "# ---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01be5ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import os\n",
    "os.makedirs(\"./rollouts\", exist_ok=True)\n",
    "mp4_path = f\"./rollouts/test.mp4\"\n",
    "video_writer = imageio.get_writer(mp4_path, fps=30)\n",
    "for img in play_imgs:\n",
    "    video_writer.append_data(img)\n",
    "video_writer.close()\n",
    "\n",
    "# Display the video in the notebook\n",
    "from IPython.display import Video, display\n",
    "display(Video(mp4_path, width=400, height=300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7665639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Union\n",
    "from trl import DPOTrainer\n",
    "\n",
    "class CustomDPOTrainer(DPOTrainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def get_winner(self, batch: dict[str, Union[list, torch.LongTensor]]) -> dict:\n",
    "        pass\n",
    "    def get_loser(self, batch: dict[str, Union[list, torch.LongTensor]]) -> dict:\n",
    "        pass\n",
    "        \n",
    "    def _prepare_dataset(\n",
    "        self,\n",
    "        dataset: Union[Dataset, IterableDataset],\n",
    "        processing_class: Union[PreTrainedTokenizerBase, BaseImageProcessor, FeatureExtractionMixin, ProcessorMixin],\n",
    "        args: DPOConfig,\n",
    "        dataset_name: str,\n",
    "    ) -> Union[Dataset, IterableDataset]:  # return dataset, which will be used in _get_dataloader\n",
    "        return dataset\n",
    "\n",
    "    @staticmethod\n",
    "    def concatenated_inputs(\n",
    "        batch: dict[str, Union[list, torch.LongTensor]], padding_value: int\n",
    "    ) -> dict[str, torch.LongTensor]:\n",
    "        pass\n",
    "\n",
    "    def concatenated_forward(\n",
    "        self, model: nn.Module, batch: dict[str, Union[list, torch.LongTensor]], is_ref_model: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Runs the given model on the given batch of inputs, concatenating the chosen and rejected inputs together.\n",
    "\n",
    "        We do this to avoid doing two forward passes, because it's faster for FSDP.\n",
    "\n",
    "        Args:\n",
    "            model:\n",
    "                Model to run the forward pass on.\n",
    "            batch:\n",
    "                Batch of input data.\n",
    "            is_ref_model:\n",
    "                Whether this method is being called for the reference model. If `True`, length desensitization is not\n",
    "                applied.\n",
    "        \"\"\"\n",
    "        return super().concatenated_forward(model, batch, is_ref_model)\n",
    "\n",
    "\n",
    "trainer = CustomDPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=ref_model,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "# trainer.is_vision_model = True\n",
    "\n",
    "trainer._signature_columns = [\n",
    "    \"prompt_input_ids\",\n",
    "    \"chosen_input_ids\",\n",
    "    \"rejected_input_ids\",\n",
    "    \"image_sizes\",\n",
    "    \"ref_chosen_logps\",\n",
    "    \"ref_rejected_logps\",\n",
    "]  ## should add \"pixel_values\" and \"pixel_attention_mask\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9dc59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM, LlamaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552c4fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始数据 \n",
    "#   ↓\n",
    "# __init__ \n",
    "#   ├── 设置 processing_class (tokenizer/processor)\n",
    "#   ├── 设置 padding_value  \n",
    "#   ├── 设置 data_collator\n",
    "#   └── 调用 _prepare_dataset\n",
    "#         ↓\n",
    "# _prepare_dataset\n",
    "#   ├── maybe_extract_prompt (提取隐式prompt)\n",
    "#   ├── maybe_apply_chat_template (应用聊天模板)  \n",
    "#   └── tokenize_row/process_row (标记化)\n",
    "#         ↓\n",
    "# get_train_dataloader/get_eval_dataloader\n",
    "#   └── compute_ref_log_probs (预计算参考对数概率，可选)\n",
    "#         ↓\n",
    "# DataCollatorForPreference.torch_call\n",
    "#   └── 批处理：转张量、填充\n",
    "#         ↓\n",
    "# concatenated_inputs  \n",
    "#   └── 连接 chosen/rejected 输入\n",
    "#         ↓\n",
    "# 模型前向传播\n",
    "\n",
    "\n",
    "# 1. DPOTrainer.__init__()\n",
    "#    ├── 设置 processing_class, padding_value, data_collator\n",
    "#    ├── 调用 _prepare_dataset() \n",
    "#    │   ├── maybe_extract_prompt()\n",
    "#    │   ├── maybe_apply_chat_template()\n",
    "#    │   └── tokenize_row/process_row()\n",
    "#    └── 调用 super().__init__() 传递处理好的数据集\n",
    "\n",
    "# 2. 训练开始：trainer.train()\n",
    "#    └── 调用 _inner_training_loop()\n",
    "\n",
    "# 3. _inner_training_loop()\n",
    "#    └── 调用 get_train_dataloader()  ← 这里！\n",
    "\n",
    "# 4. get_train_dataloader()\n",
    "#    └── 调用 _get_dataloader()  ← 这里！\n",
    "\n",
    "# 5. _get_dataloader()\n",
    "#    └── 调用 _remove_unused_columns()  ← 最终调用位置！\n",
    "\n",
    "# 6. DataLoader 创建完成，开始训练循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36da10b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dpo_trainer.train()\n",
    "# │\n",
    "# ├─ Trainer.train() [基类方法]\n",
    "# │   │\n",
    "# │   ├─ 初始化训练环境\n",
    "# │   ├─ 加载检查点 (如果有)\n",
    "# │   │\n",
    "# │   └─ _inner_training_loop()\n",
    "# │       │\n",
    "# │       ├─ 创建训练数据加载器\n",
    "# │       ├─ 初始化优化器和调度器\n",
    "# │       │\n",
    "# │       └─ 主训练循环:\n",
    "# │           │\n",
    "# │           for epoch in epochs:\n",
    "# │               for update_step in total_updates:\n",
    "# │                   for inputs in batch_samples:\n",
    "# │                       │\n",
    "# │                       └─ training_step(model, inputs)\n",
    "# │                           │\n",
    "# │                           ├─ model.train()\n",
    "# │                           ├─ _prepare_inputs(inputs)\n",
    "# │                           │\n",
    "# │                           └─ compute_loss(model, inputs) [DPO重写]\n",
    "# │                               │\n",
    "# │                               └─ get_batch_loss_metrics(model, batch)\n",
    "# │                                   │\n",
    "# │                                   ├─ 判断是否使用Liger优化\n",
    "# │                                   │\n",
    "# │                                   ├─ [路径1: 使用Liger] _compute_loss_liger()\n",
    "# │                                   │   │\n",
    "# │                                   │   ├─ concatenated_inputs() - 合并chosen/rejected数据\n",
    "# │                                   │   ├─ 模型前向传播获取hidden states\n",
    "# │                                   │   ├─ 获取参考模型权重\n",
    "# │                                   │   └─ LigerFusedLinearDPOLoss() - 计算DPO loss\n",
    "# │                                   │\n",
    "# │                                   └─ [路径2: 标准流程] \n",
    "# │                                       │\n",
    "# │                                       ├─ concatenated_forward(model, batch)\n",
    "# │                                       │   │\n",
    "# │                                       │   ├─ concatenated_inputs() - 合并数据\n",
    "# │                                       │   ├─ 模型前向传播\n",
    "# │                                       │   ├─ 计算logits和attention mask\n",
    "# │                                       │   ├─ selective_log_softmax() - 计算log概率\n",
    "# │                                       │   └─ 返回chosen_logps, rejected_logps\n",
    "# │                                       │\n",
    "# │                                       ├─ compute_ref_log_probs(batch) \n",
    "# │                                       │   │\n",
    "# │                                       │   ├─ 如果batch中有预计算的ref logps则直接使用\n",
    "# │                                       │   └─ 否则用参考模型计算:\n",
    "# │                                       │       ├─ null_ref_context() - PEFT适配器切换\n",
    "# │                                       │       └─ concatenated_forward(ref_model, batch)\n",
    "# │                                       │\n",
    "# │                                       └─ dpo_loss(chosen_logps, rejected_logps, ref_chosen_logps, ref_rejected_logps)\n",
    "# │                                           │\n",
    "# │                                           ├─ 计算log ratios\n",
    "# │                                           ├─ 应用不同的loss类型 (sigmoid, hinge, ipo等)\n",
    "# │                                           ├─ 计算rewards\n",
    "# │                                           └─ 返回losses, chosen_rewards, rejected_rewards\n",
    "# │\n",
    "# └─ 返回训练结果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
