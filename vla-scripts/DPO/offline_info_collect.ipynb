{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d347348",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e52a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 15:26:19.978174: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-22 15:26:19.978208: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-22 15:26:19.980219: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-22 15:26:19.989855: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-22 15:26:20.876938: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)\n",
      "/home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, torch\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional, Union, List\n",
    "import types\n",
    "import draccus\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from libero.libero import benchmark\n",
    "import cv2\n",
    "import wandb\n",
    "from experiments.robot.libero.libero_utils import get_libero_env\n",
    "\n",
    "# Append current directory so that interpreter can find experiments.robot\n",
    "sys.path.append(\"../..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5482eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GenerateConfig:\n",
    "    \"\"\"Configuration for OpenVLA inference on LIBERO tasks.\"\"\"\n",
    "    # fmt: off\n",
    "\n",
    "    #################################################################################################################\n",
    "    # Model-specific parameters\n",
    "    #################################################################################################################\n",
    "    model_family: str = \"openvla\"                    # Model family\n",
    "    pretrained_checkpoint: Union[str, Path] = \"/mnt/sda/home/zijianwang/openvla/FT_res/openvla-7b-finetuned-libero-10+libero_10_no_noops+b4+lr-0.0005+lora-r48+dropout-0.0--image_aug--2025-07-18_19-26-25\"     # Pretrained checkpoint path\n",
    "    load_in_8bit: bool = False                       # (For OpenVLA only) Load with 8-bit quantization\n",
    "    load_in_4bit: bool = False                       # (For OpenVLA only) Load with 4-bit quantization\n",
    "\n",
    "    center_crop: bool = True                         # Center crop? (if trained w/ random crop image aug)\n",
    "\n",
    "    #################################################################################################################\n",
    "    # LIBERO environment-specific parameters\n",
    "    #################################################################################################################\n",
    "    task_suite_name: str = \"libero_10\"             # Task suite. Options: libero_spatial, libero_object, libero_goal, libero_10, libero_90\n",
    "    num_steps_wait: int = 10                         # Number of steps to wait for objects to stabilize in sim\n",
    "    num_trials_per_task: int = 50                    # Number of rollouts per task\n",
    "\n",
    "    #################################################################################################################\n",
    "    # Utils\n",
    "    #################################################################################################################\n",
    "    run_id_note: Optional[str] = None                # Extra note to add in run ID for logging\n",
    "    local_log_dir: str = \"./experiments/logs\"        # Local directory for eval logs\n",
    "\n",
    "    use_wandb: bool = False                          # Whether to also log results in Weights & Biases\n",
    "    wandb_project: str = \"YOUR_WANDB_PROJECT\"        # Name of W&B project to log to (use default!)\n",
    "    wandb_entity: str = \"YOUR_WANDB_ENTITY\"          # Name of entity to log under\n",
    "\n",
    "    seed: int = 7                                    # Random Seed (for reproducibility)\n",
    "    device: str = \"cuda:1\"                           # Device to use for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eb88998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize configuration\n",
    "cfg = GenerateConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9797ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "id2caption = json.load(open(\"/mnt/sda/home/zijianwang/openvla/vla-scripts/DPO/data/id2caption.json\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53f0b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /mnt/sda/home/zijianwang/openvla/rollouts/2025_07_18\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Path to rollouts directory\n",
    "rollout_dir = \"/mnt/sda/home/zijianwang/openvla/rollouts/2025_07_18\"\n",
    "\n",
    "# Regular expression pattern to extract information from filenames\n",
    "pattern = r\"episode=(\\d+)--success=(True|False)--task=(.+)\\.mp4$\"\n",
    "\n",
    "results = []\n",
    "\n",
    "# Walk through directory\n",
    "for filename in os.listdir(rollout_dir):\n",
    "    match = re.search(pattern, filename)\n",
    "    if match:\n",
    "        episode_num = int(match.group(1))\n",
    "        success = match.group(2) == \"True\"\n",
    "        task_desc = match.group(3)\n",
    "        \n",
    "        # Find corresponding task suite and task id\n",
    "        found = False\n",
    "        for suite_name, tasks in id2caption.items():\n",
    "            for task_id, caption in tasks.items():\n",
    "                if task_desc in caption.replace(\" \", \"_\"):\n",
    "                    found = True\n",
    "                    # Adjust episode number: convert from global (0-499) to per-task (0-49)\n",
    "                    # Each task has 50 episodes, so episode_within_task = episode_num % 50\n",
    "                    episode_within_task = (episode_num-1) % 50\n",
    "                    results.append({\n",
    "                        \"filename\": filename,\n",
    "                        \"episode\": episode_within_task,\n",
    "                        \"success\": success,\n",
    "                        \"task_suite\": suite_name,\n",
    "                        \"task_id\": task_id,\n",
    "                        \"task_description\": caption\n",
    "                    })\n",
    "                    break\n",
    "            if found:\n",
    "                break\n",
    "# Filter successful trajectories\n",
    "successful_results = [r for r in results if r['success']]\n",
    "# Save successful results to JSON file\n",
    "\n",
    "with open('successful_trajectories.json', 'w') as f:\n",
    "    json.dump(successful_results, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "747f368c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode mapping created:\n",
      "1 -> 0\n",
      "50 -> 49\n",
      "51 -> 0\n",
      "100 -> 49\n",
      "101 -> 0\n",
      "150 -> 49\n",
      "151 -> 0\n",
      "200 -> 49\n"
     ]
    }
   ],
   "source": [
    "# Create mapping from 1-200 to 0-49 (repeating pattern)\n",
    "# 1-50 -> 0-49, 51-100 -> 0-49, 101-150 -> 0-49, 151-200 -> 0-49\n",
    "episode_mapping = {}\n",
    "for i in range(1, 201):\n",
    "    episode_mapping[i] = (i - 1) % 50\n",
    "\n",
    "print(\"Episode mapping created:\")\n",
    "print(f\"1 -> {episode_mapping[1]}\")\n",
    "print(f\"50 -> {episode_mapping[50]}\")\n",
    "print(f\"51 -> {episode_mapping[51]}\")\n",
    "print(f\"100 -> {episode_mapping[100]}\")\n",
    "print(f\"101 -> {episode_mapping[101]}\")\n",
    "print(f\"150 -> {episode_mapping[150]}\")\n",
    "print(f\"151 -> {episode_mapping[151]}\")\n",
    "print(f\"200 -> {episode_mapping[200]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
