{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dd6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c007dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_CACHE\"] = \"/mnt/sda/home/zijianwang/HF_CACHE\"\n",
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import draccus\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import tqdm\n",
    "from accelerate import PartialState\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor, BitsAndBytesConfig\n",
    "from transformers import AutoConfig, AutoImageProcessor\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "\n",
    "import wandb\n",
    "from prismatic.models.backbones.llm.prompting import PurePromptBuilder, VicunaV15ChatPromptBuilder\n",
    "from prismatic.util.data_utils import PaddedCollatorForActionPrediction\n",
    "from prismatic.vla.action_tokenizer import ActionTokenizer\n",
    "from prismatic.vla.datasets import RLDSBatchTransform, RLDSDataset, EpisodicRLDSDataset\n",
    "from prismatic.vla.datasets.rlds.utils.data_utils import save_dataset_statistics\n",
    "\n",
    "from prismatic.extern.hf.configuration_prismatic import OpenVLAConfig\n",
    "from prismatic.extern.hf.modeling_prismatic import OpenVLAForActionPrediction\n",
    "from prismatic.extern.hf.processing_prismatic import PrismaticImageProcessor, PrismaticProcessor\n",
    "\n",
    "# Sane Defaults\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ff5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoConfig.register(\"openvla\", OpenVLAConfig)\n",
    "AutoImageProcessor.register(OpenVLAConfig, PrismaticImageProcessor)\n",
    "AutoProcessor.register(OpenVLAConfig, PrismaticProcessor)\n",
    "AutoModelForVision2Seq.register(OpenVLAConfig, OpenVLAForActionPrediction)\n",
    "processor = AutoProcessor.from_pretrained(\"openvla/openvla-7b\", trust_remote_code=True)\n",
    "action_tokenizer = ActionTokenizer(processor.tokenizer)\n",
    "vocab_size = action_tokenizer.vocab_size\n",
    "print(\"词表大小:\", vocab_size)\n",
    "vla_model_config = OpenVLAConfig.from_pretrained(\"openvla/openvla-7b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20238e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_transform = RLDSBatchTransform(\n",
    "    action_tokenizer,\n",
    "    processor.tokenizer,\n",
    "    image_transform=processor.image_processor.apply_transform,\n",
    "    prompt_builder_fn=PurePromptBuilder if \"v01\" not in \"openvla/openvla-7b\" else VicunaV15ChatPromptBuilder,\n",
    ")\n",
    "\n",
    "vla_dataset = RLDSDataset(\n",
    "    \"/mnt/sda/home/zijianwang/openvla/modified_libero_rlds\",\n",
    "    \"libero_goal_no_noops\",\n",
    "    batch_transform,\n",
    "    resize_resolution=tuple(vla_model_config.image_sizes),\n",
    "    shuffle_buffer_size=100_000,\n",
    "    image_aug=True,\n",
    ")\n",
    "\n",
    "episodic_vla_dataset = EpisodicRLDSDataset(\n",
    "    \"/mnt/sda/home/zijianwang/openvla/modified_libero_rlds\",\n",
    "    \"libero_object_no_noops\", # \"libero_goal_no_noops\", libero_10, libero_spatial, libero_object, libero_goal\n",
    "    batch_transform,\n",
    "    resize_resolution=tuple(vla_model_config.image_sizes),\n",
    "    shuffle_buffer_size=100_000,\n",
    "    image_aug=False,\n",
    "    if_random_start=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c1964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import imageio, os\n",
    "import numpy as np\n",
    "from infer_utils import predict_CoA, add_text_to_image\n",
    "\n",
    "task_desc = json.load(open('task_descriptions.json', 'r'))\n",
    "i = 0\n",
    "found_tasks = set()  # 用于跟踪已找到的任务\n",
    "task_description_counts = {}  # 用于跟踪每个任务描述出现的次数\n",
    "total_tasks = sum(len(tasks) for tasks in task_desc.values())  # 计算总任务数\n",
    "\n",
    "for data in episodic_vla_dataset:\n",
    "    print(f\"************* Processing episode {i} *************\")\n",
    "    text = processor.decode(data[\"text\"])\n",
    "    # print(text)\n",
    "    pattern = r'In:\\s*(.*?)\\s*Out:'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_text = match.group(1).strip()\n",
    "        # 移除\"What action should the robot take to\"前缀和末尾的问号\n",
    "        if extracted_text.startswith(\"What action should the robot take to \"):\n",
    "            extracted_text = extracted_text[len(\"What action should the robot take to \"):]\n",
    "        if extracted_text.endswith(\"?\"):\n",
    "            extracted_text = extracted_text[:-1]\n",
    "    print(extracted_text)\n",
    "    # 验证 task_desc 的 value 中是否包含了 extracted_text\n",
    "    found_match = False\n",
    "    for task_name, tasks in task_desc.items():\n",
    "        for task_id, description in tasks.items():\n",
    "            if extracted_text in description or description in extracted_text:\n",
    "                print(f\"Found match in {task_name}, task {task_id}: {description}\")\n",
    "                found_task_name = task_name\n",
    "                found_task_id = task_id\n",
    "                found_match = True\n",
    "                found_tasks.add((task_name, task_id))  # 记录已找到的任务\n",
    "                \n",
    "                # 记录任务描述出现的次数\n",
    "                task_key = f\"{task_name}_{task_id}\"\n",
    "                if task_key not in task_description_counts:\n",
    "                    task_description_counts[task_key] = 0\n",
    "                task_description_counts[task_key] += 1\n",
    "                \n",
    "                break\n",
    "        if found_match:\n",
    "            break\n",
    "    \n",
    "    if not found_match:\n",
    "        print(f\"No match found for: {extracted_text}\")\n",
    "    action_ids = data[\"action\"]\n",
    "    action_ids = np.array(action_ids) \n",
    "    imgs = data[\"replay_images\"] #List[np.ndarray]\n",
    "    # 声明 action_ids 的长度是 imgs 的 8 倍\n",
    "    assert len(action_ids) == len(imgs) * 8, f\"action_ids length {len(action_ids)} should be 8 times imgs length {len(imgs)}\"\n",
    "    # 把action_ids每8个分为1组\n",
    "    action_ids_grouped = [action_ids[i:i+8] for i in range(0, len(action_ids), 8)]\n",
    "    \n",
    "    # 使用任务描述出现次数的负数作为episode编号\n",
    "    task_key = f\"{found_task_name}_{found_task_id}\"\n",
    "    episode_num = -task_description_counts[task_key]\n",
    "    trajectory_save_dir = f\"winner_trajectory/{found_task_name}/task_{found_task_id}_episode_{episode_num}_success/\"\n",
    "    os.makedirs(trajectory_save_dir, exist_ok=True)\n",
    "\n",
    "    mp4_path = os.path.join(trajectory_save_dir, f\"Avideo_{len(imgs)}.mp4\")\n",
    "    video_writer = imageio.get_writer(mp4_path, fps=30)\n",
    "    for step, img in enumerate(imgs[:]):    \n",
    "        # img = add_text_to_image(img, 1, step)\n",
    "        video_writer.append_data(img)\n",
    "    video_writer.close()\n",
    "\n",
    "    # # Save obs and action_ids with timestep information\n",
    "    \n",
    "    for j in range(len(imgs)):\n",
    "        img = imgs[j]\n",
    "        info = {\n",
    "            \"obs\": img,\n",
    "            \"action_ids\": action_ids_grouped[j],\n",
    "        }\n",
    "        obs_filename = os.path.join(trajectory_save_dir, f\"step_{j}.pkl\")\n",
    "        with open(obs_filename, 'wb') as f:\n",
    "            pickle.dump(info, f)\n",
    "    print(f\"Saved {obs_filename}\")\n",
    "    i += 1\n",
    "    \n",
    "    # 检查终止条件：所有任务都被找到或遍历了1000次\n",
    "    if len(found_tasks) >= total_tasks or i >= 1000:\n",
    "        print(f\"Stopping loop: found {len(found_tasks)}/{total_tasks} tasks, processed {i} episodes\")\n",
    "        break\n",
    "    \n",
    "    # if i > 1000:\n",
    "    #     break\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a1dc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest 10 trajectories for each task:\n",
      "\n",
      "Task 0:\n",
      "  task_0_episode_46_success: 249 steps\n",
      "  task_0_episode_21_success: 249 steps\n",
      "  task_0_episode_-7_success: 250 steps\n",
      "  task_0_episode_-3_success: 255 steps\n",
      "  task_0_episode_1_success: 260 steps\n",
      "  task_0_episode_-2_success: 265 steps\n",
      "  task_0_episode_25_success: 266 steps\n",
      "  task_0_episode_33_success: 266 steps\n",
      "  task_0_episode_29_success: 266 steps\n",
      "  task_0_episode_23_success: 269 steps\n",
      "\n",
      "Task 1:\n",
      "  task_1_episode_2_success: 223 steps\n",
      "  task_1_episode_42_success: 226 steps\n",
      "  task_1_episode_27_success: 229 steps\n",
      "  task_1_episode_45_success: 233 steps\n",
      "  task_1_episode_-8_success: 234 steps\n",
      "  task_1_episode_44_success: 235 steps\n",
      "  task_1_episode_-13_success: 237 steps\n",
      "  task_1_episode_37_success: 238 steps\n",
      "  task_1_episode_-5_success: 238 steps\n",
      "  task_1_episode_-14_success: 239 steps\n",
      "\n",
      "Task 2:\n",
      "  task_2_episode_4_success: 206 steps\n",
      "  task_2_episode_22_success: 210 steps\n",
      "  task_2_episode_15_success: 228 steps\n",
      "  task_2_episode_25_success: 229 steps\n",
      "  task_2_episode_28_success: 237 steps\n",
      "  task_2_episode_2_success: 259 steps\n",
      "  task_2_episode_5_success: 265 steps\n",
      "  task_2_episode_45_success: 266 steps\n",
      "  task_2_episode_0_success: 272 steps\n",
      "  task_2_episode_16_success: 281 steps\n",
      "\n",
      "Task 3:\n",
      "  task_3_episode_-9_success: 217 steps\n",
      "  task_3_episode_7_success: 217 steps\n",
      "  task_3_episode_-12_success: 221 steps\n",
      "  task_3_episode_-11_success: 227 steps\n",
      "  task_3_episode_-2_success: 230 steps\n",
      "  task_3_episode_-1_success: 230 steps\n",
      "  task_3_episode_-7_success: 235 steps\n",
      "  task_3_episode_-4_success: 237 steps\n",
      "  task_3_episode_-6_success: 240 steps\n",
      "  task_3_episode_34_success: 243 steps\n",
      "\n",
      "Task 4:\n",
      "  task_4_episode_32_success: 201 steps\n",
      "  task_4_episode_8_success: 212 steps\n",
      "  task_4_episode_36_success: 217 steps\n",
      "  task_4_episode_38_success: 225 steps\n",
      "  task_4_episode_20_success: 225 steps\n",
      "  task_4_episode_31_success: 226 steps\n",
      "  task_4_episode_27_success: 231 steps\n",
      "  task_4_episode_49_success: 232 steps\n",
      "  task_4_episode_-3_success: 233 steps\n",
      "  task_4_episode_-1_success: 233 steps\n",
      "\n",
      "Task 5:\n",
      "  task_5_episode_22_success: 154 steps\n",
      "  task_5_episode_43_success: 156 steps\n",
      "  task_5_episode_8_success: 156 steps\n",
      "  task_5_episode_6_success: 162 steps\n",
      "  task_5_episode_-13_success: 162 steps\n",
      "  task_5_episode_11_success: 164 steps\n",
      "  task_5_episode_-2_success: 165 steps\n",
      "  task_5_episode_9_success: 167 steps\n",
      "  task_5_episode_-3_success: 167 steps\n",
      "  task_5_episode_1_success: 167 steps\n",
      "\n",
      "Task 6:\n",
      "  task_6_episode_3_success: 191 steps\n",
      "  task_6_episode_4_success: 193 steps\n",
      "  task_6_episode_22_success: 205 steps\n",
      "  task_6_episode_-6_success: 220 steps\n",
      "  task_6_episode_2_success: 220 steps\n",
      "  task_6_episode_49_success: 221 steps\n",
      "  task_6_episode_40_success: 226 steps\n",
      "  task_6_episode_-8_success: 226 steps\n",
      "  task_6_episode_-1_success: 228 steps\n",
      "  task_6_episode_33_success: 229 steps\n",
      "\n",
      "Task 7:\n",
      "  task_7_episode_15_success: 215 steps\n",
      "  task_7_episode_-1_success: 236 steps\n",
      "  task_7_episode_42_success: 238 steps\n",
      "  task_7_episode_22_success: 240 steps\n",
      "  task_7_episode_10_success: 242 steps\n",
      "  task_7_episode_18_success: 245 steps\n",
      "  task_7_episode_-10_success: 250 steps\n",
      "  task_7_episode_38_success: 250 steps\n",
      "  task_7_episode_46_success: 255 steps\n",
      "  task_7_episode_45_success: 259 steps\n",
      "\n",
      "Task 8:\n",
      "  task_8_episode_-7_success: 373 steps\n",
      "  task_8_episode_0_success: 375 steps\n",
      "  task_8_episode_-1_success: 388 steps\n",
      "  task_8_episode_-9_success: 389 steps\n",
      "  task_8_episode_-2_success: 392 steps\n",
      "  task_8_episode_5_success: 400 steps\n",
      "  task_8_episode_-8_success: 408 steps\n",
      "  task_8_episode_-6_success: 419 steps\n",
      "  task_8_episode_-4_success: 450 steps\n",
      "  task_8_episode_22_success: 453 steps\n",
      "\n",
      "Task 9:\n",
      "  task_9_episode_-7_success: 239 steps\n",
      "  task_9_episode_39_success: 241 steps\n",
      "  task_9_episode_-6_success: 247 steps\n",
      "  task_9_episode_-1_success: 248 steps\n",
      "  task_9_episode_-10_success: 255 steps\n",
      "  task_9_episode_-3_success: 265 steps\n",
      "  task_9_episode_-12_success: 268 steps\n",
      "  task_9_episode_34_success: 276 steps\n",
      "  task_9_episode_-4_success: 278 steps\n",
      "  task_9_episode_45_success: 282 steps\n"
     ]
    }
   ],
   "source": [
    "import re, os\n",
    "from collections import defaultdict\n",
    "\n",
    "data_path = \"/mnt/sda/home/zijianwang/openvla/vla-scripts/DPO/winner_trajectory/libero_10\"\n",
    "task_trajectories = defaultdict(list)\n",
    "\n",
    "for folder_name in os.listdir(data_path):\n",
    "    match = re.search(r\"task_(\\d+)_episode_(-?\\d+)_(failure|success)\", folder_name)\n",
    "    if match and match.group(3) == \"success\":\n",
    "        task_num = match.group(1)\n",
    "        # Count pkl files in this trajectory folder\n",
    "        trajectory_folder_path = os.path.join(data_path, folder_name)\n",
    "        pkl_files = [f for f in os.listdir(trajectory_folder_path) if f.endswith(\".pkl\")]\n",
    "        traj_len = len(pkl_files)\n",
    "        task_trajectories[task_num].append((folder_name, traj_len))\n",
    "\n",
    "# For each task, sort by trajectory length and get the shortest 10\n",
    "print(\"Shortest 10 trajectories for each task:\")\n",
    "for task_num in sorted(task_trajectories.keys()):\n",
    "    task_trajectories[task_num].sort(key=lambda x: x[1])\n",
    "    shortest_10 = task_trajectories[task_num][:10]\n",
    "    \n",
    "    print(f\"\\nTask {task_num}:\")\n",
    "    for folder_name, traj_len in shortest_10:\n",
    "        print(f\"  {folder_name}: {traj_len} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc63967",
   "metadata": {},
   "source": [
    "# Get Task info from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed9fd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.robot.libero.libero_utils import get_libero_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f32b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libero.libero import benchmark\n",
    "benchmark_dict = benchmark.get_benchmark_dict()\n",
    "print(benchmark_dict.keys())\n",
    "task_desc = {}\n",
    "task_names = ['libero_spatial', 'libero_object', 'libero_goal', 'libero_10']\n",
    "for task_name in task_names:\n",
    "    task_suite = benchmark_dict[task_name]()  #libero_spatial, libero_object, libero_goal, libero_10, libero_90\n",
    "    num_tasks_in_suite = task_suite.n_tasks\n",
    "    print(f\"Number of tasks in {task_name}: {num_tasks_in_suite}\")\n",
    "    task_desc[task_name] = {}\n",
    "    for task_id in range(num_tasks_in_suite):\n",
    "        task = task_suite.get_task(task_id)\n",
    "        env, task_description = get_libero_env(task, \"openvla\", resolution=256)\n",
    "        print(f\"Task {task_id} description: {task_description}\")\n",
    "        task_desc[task_name][task_id] = task_description"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
