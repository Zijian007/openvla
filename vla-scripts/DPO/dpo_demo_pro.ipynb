{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OpenVLA DPO Training Demo - Professional Version\n",
        "\n",
        "This notebook provides a modular implementation of Direct Preference Optimization (DPO) training for OpenVLA models. Each section can be run independently for debugging and testing purposes.\n",
        "\n",
        "## Overview\n",
        "1. **Environment Setup** - Import libraries and configure paths\n",
        "2. **Configuration** - Set training parameters and model configs\n",
        "3. **Model Loading** - Load policy and reference models\n",
        "4. **Data Loading** - Setup datasets and data loaders\n",
        "5. **DPO Training** - Main training loop\n",
        "6. **Testing & Debugging** - Utilities for debugging each component\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup and Imports\n",
        "\n",
        "Import all necessary libraries and setup the Python path for accessing local modules.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TO DO\n",
        "## 1. 修改计算logprob时的mask, 不算separate action token的loss.\n",
        "## 2. 对一个stream中每个action units赋予不同的weights, according to spatial distance.\n",
        "## 3. 同时具备离线和在线的loser 轨迹采集\n",
        "## 4. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2           "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added to Python path: /mnt/sda/home/zijianwang/openvla/vla-scripts/DPO/../..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-08-21 20:29:49.417604: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-08-21 20:29:49.417798: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-08-21 20:29:49.606938: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-08-21 20:29:50.129667: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-08-21 20:29:52.520568: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
            "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
            "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/zijianwang/miniconda3/envs/openvla/lib/python3.10/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Successfully imported local modules\n",
            "✓ Successfully imported external modules\n",
            "\n",
            "GPU Information:\n",
            "CUDA available: True\n",
            "GPU count: 4\n",
            "  GPU 0: NVIDIA GeForce RTX 4090\n",
            "    Memory: 25.4 GB\n",
            "  GPU 1: NVIDIA GeForce RTX 4090\n",
            "    Memory: 25.4 GB\n",
            "  GPU 2: NVIDIA GeForce RTX 4090\n",
            "    Memory: 25.4 GB\n",
            "  GPU 3: NVIDIA RTX A6000\n",
            "    Memory: 51.0 GB\n",
            "\n",
            "==================================================\n",
            "Environment setup completed!\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "DPO Training Demo - Environment Setup\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add the parent directories to Python path for imports\n",
        "current_dir = os.getcwd()\n",
        "parent_dir = os.path.join(current_dir, \"..\", \"..\")\n",
        "sys.path.append(parent_dir)\n",
        "print(f\"Added to Python path: {parent_dir}\")\n",
        "\n",
        "# Core imports\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from trl.trainer.dpo_trainer import DataCollatorForPreference\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from experiments.robot.libero.libero_utils import (\n",
        "    get_libero_dummy_action,\n",
        "    get_libero_env,\n",
        "    get_libero_image,\n",
        "    quat2axisangle,\n",
        "    save_rollout_video_CoA,\n",
        ")\n",
        "\n",
        "# Local imports\n",
        "try:\n",
        "    from src.config import GenerateConfig\n",
        "    from src.model_utils import setup_vla_model_with_lora, setup_model_and_config, setup_logging_and_environment\n",
        "    from src.training_utils import train_dpo, compute_log_probs, dpo_loss\n",
        "    from src.data_process import TrajectoryDataset\n",
        "    print(\"✓ Successfully imported local modules\")\n",
        "except ImportError as e:\n",
        "    print(f\"✗ Failed to import local modules: {e}\")\n",
        "    print(\"Please ensure you're running from the correct directory\")\n",
        "\n",
        "# External imports  \n",
        "try:\n",
        "    from experiments.robot.robot_utils import get_model\n",
        "    print(\"✓ Successfully imported external modules\")\n",
        "except ImportError as e:\n",
        "    print(f\"✗ Failed to import external modules: {e}\")\n",
        "\n",
        "# Check GPU availability\n",
        "print(f\"\\nGPU Information:\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "        print(f\"    Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Environment setup completed!\")\n",
        "print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration Setup\n",
        "\n",
        "Configure all training parameters. You can modify these parameters easily for different experiments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating configuration...\n",
            "\n",
            "==================================================\n",
            "CONFIGURATION SUMMARY\n",
            "==================================================\n",
            "Policy Device: cuda:0\n",
            "Reference Device: cuda:1\n",
            "Max Steps: 100\n",
            "Batch Size: 1\n",
            "Learning Rate: 0.0005\n",
            "DPO Beta: 0.1\n",
            "Stream Length: 10\n",
            "Use WandB: False\n",
            "Task Number: 1\n",
            "\n",
            "Path Configuration:\n",
            "Root Dir: /mnt/sda/home/zijianwang\n",
            "Pretrained Checkpoint: /mnt/sda/home/zijianwang/openvla/FT_res/openvla-7b-finetuned-libero-10+libero_10_no_noops+b4+lr-0.0005+lora-r48+dropout-0.0--image_aug--2025-07-18_19-26-25\n",
            "LoRA Path: /mnt/sda/home/zijianwang/openvla/adapter_tmp_dir/openvla-7b-finetuned-libero-10+libero_10_no_noops+b4+lr-0.0005+lora-r48+dropout-0.0--image_aug--2025-07-18_19-26-25\n",
            "Winner Trajectory Path: /mnt/sda/home/zijianwang/openvla/vla-scripts/DPO/winner_trajectory\n",
            "Adapter Tmp Dir: /mnt/sda/home/zijianwang/openvla/DPO_adapter_tmp_dir\n",
            "Run Root Dir: /mnt/sda/home/zijianwang/openvla/DPO_res\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Configuration Setup - Modify parameters here for different experiments\n",
        "\"\"\"\n",
        "\n",
        "# ====== TRAINING PARAMETERS ======\n",
        "DEVICE_POLICY = \"cuda:0\"  # Device for policy model\n",
        "DEVICE_REF = \"cuda:1\"     # Device for reference model\n",
        "MAX_STEPS = 100           # Maximum training steps (reduced for demo)\n",
        "BATCH_SIZE = 1            # Training batch size\n",
        "LEARNING_RATE = 0.0005    # Learning rate\n",
        "DPO_BETA = 0.1           # DPO beta parameter\n",
        "STREAM_LENGTH = 10        # Stream length for trajectory processing\n",
        "\n",
        "# ====== WANDB CONFIGURATION ======\n",
        "USE_WANDB = False         # Set to True to enable Weights & Biases logging\n",
        "WANDB_PROJECT = \"openvla_CoA_DPO_demo\"\n",
        "WANDB_ENTITY = \"15652388600\"\n",
        "RUN_ID_NOTE = \"notebook_demo\"\n",
        "\n",
        "# ====== PATH CONFIGURATION ======\n",
        "ROOT_DIR = \"/mnt/sda/home/zijianwang\"\n",
        "\n",
        "\n",
        "# ROOT_DIR=\"/mnt/sda/home/zijianwang\"\n",
        "# PRETRAINED_CHECKPOINT=\"${ROOT_DIR}/openvla/FT_res/openvla-7b-finetuned-libero-10+libero_10_no_noops+b4+lr-0.0005+lora-r48+dropout-0.0--image_aug--2025-07-18_19-26-25\"\n",
        "# LORA_PATH=\"${ROOT_DIR}/openvla/adapter_tmp_dir/openvla-7b-finetuned-libero-10+libero_10_no_noops+b4+lr-0.0005+lora-r48+dropout-0.0--image_aug--2025-07-18_19-26-25\"\n",
        "# BASE_VLA_PATH=\"${ROOT_DIR}/HF_CACHE/openvla-7b-finetuned-libero-10\"\n",
        "# WINNER_TRAJECTORY_PATH=\"${ROOT_DIR}/openvla/vla-scripts/DPO/winner_trajectory\"\n",
        "# ADAPTER_TMP_DIR=\"${ROOT_DIR}/openvla/DPO_adapter_tmp_dir\"\n",
        "# RUN_ROOT_DIR=\"${ROOT_DIR}/openvla/DPO_res\"\n",
        "\n",
        "# Optional: Override default paths (leave empty to use defaults)\n",
        "PRETRAINED_CHECKPOINT = f\"{ROOT_DIR}/openvla/FT_res/openvla-7b-finetuned-libero-10+libero_10_no_noops+b4+lr-0.0005+lora-r48+dropout-0.0--image_aug--2025-07-18_19-26-25\"\n",
        "LORA_PATH = f\"{ROOT_DIR}/openvla/adapter_tmp_dir/openvla-7b-finetuned-libero-10+libero_10_no_noops+b4+lr-0.0005+lora-r48+dropout-0.0--image_aug--2025-07-18_19-26-25\"\n",
        "BASE_VLA_PATH = f\"{ROOT_DIR}/HF_CACHE/openvla-7b-finetuned-libero-10\"\n",
        "WINNER_TRAJECTORY_PATH = f\"{ROOT_DIR}/openvla/vla-scripts/DPO/winner_trajectory\"\n",
        "ADAPTER_TMP_DIR = f\"{ROOT_DIR}/openvla/DPO_adapter_tmp_dir\"\n",
        "RUN_ROOT_DIR = f\"{ROOT_DIR}/openvla/DPO_res\"\n",
        "TASK_NUM = 1            # Set to specific task number or None for all tasks\n",
        "# Create configuration objects\n",
        "print(\"Creating configuration...\")\n",
        "\n",
        "# Policy model configuration\n",
        "model_cfg = GenerateConfig(\n",
        "    root_dir=ROOT_DIR,\n",
        "    device=DEVICE_POLICY,\n",
        "    max_steps=MAX_STEPS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    dpo_beta=DPO_BETA,\n",
        "    stream_length=STREAM_LENGTH,\n",
        "    use_wandb=USE_WANDB,\n",
        "    wandb_project=WANDB_PROJECT,\n",
        "    wandb_entity=WANDB_ENTITY,\n",
        "    run_id_note=RUN_ID_NOTE,\n",
        "    grad_accumulation_steps=1,\n",
        "    pretrained_checkpoint=PRETRAINED_CHECKPOINT,\n",
        "    lora_path=LORA_PATH,\n",
        "    base_vla_path=BASE_VLA_PATH,\n",
        "    winner_trajectory_path=WINNER_TRAJECTORY_PATH,\n",
        "    adapter_tmp_dir=ADAPTER_TMP_DIR,\n",
        "    run_root_dir=RUN_ROOT_DIR,\n",
        "    task_num=TASK_NUM\n",
        ")\n",
        "\n",
        "# Reference model configuration\n",
        "ref_config = GenerateConfig(\n",
        "    root_dir=ROOT_DIR,\n",
        "    device=DEVICE_REF,\n",
        "    pretrained_checkpoint=PRETRAINED_CHECKPOINT,\n",
        "    lora_path=LORA_PATH,\n",
        "    base_vla_path=BASE_VLA_PATH,\n",
        "    winner_trajectory_path=WINNER_TRAJECTORY_PATH,\n",
        "    adapter_tmp_dir=ADAPTER_TMP_DIR,\n",
        "    run_root_dir=RUN_ROOT_DIR\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CONFIGURATION SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Policy Device: {model_cfg.device}\")\n",
        "print(f\"Reference Device: {ref_config.device}\")\n",
        "print(f\"Max Steps: {model_cfg.max_steps}\")\n",
        "print(f\"Batch Size: {model_cfg.batch_size}\")\n",
        "print(f\"Learning Rate: {model_cfg.learning_rate}\")\n",
        "print(f\"DPO Beta: {model_cfg.dpo_beta}\")\n",
        "print(f\"Stream Length: {model_cfg.stream_length}\")\n",
        "print(f\"Use WandB: {model_cfg.use_wandb}\")\n",
        "print(f\"Task Number: {model_cfg.task_num if model_cfg.task_num else 'All tasks'}\")\n",
        "print(\"\\nPath Configuration:\")\n",
        "print(f\"Root Dir: {model_cfg.root_dir}\")\n",
        "print(f\"Pretrained Checkpoint: {model_cfg.pretrained_checkpoint}\")\n",
        "print(f\"LoRA Path: {model_cfg.lora_path}\")\n",
        "print(f\"Winner Trajectory Path: {model_cfg.winner_trajectory_path}\")\n",
        "print(f\"Adapter Tmp Dir: {model_cfg.adapter_tmp_dir}\")\n",
        "print(f\"Run Root Dir: {model_cfg.run_root_dir}\")\n",
        "print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Loading\n",
        "\n",
        "Load the policy model (with LoRA) and reference model. This section handles device placement and model initialization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting model loading...\n",
            "This may take several minutes depending on model size and device speed.\n",
            "\n",
            "------------------------------\n",
            "[1/2] Loading policy model (with LoRA)...\n",
            "Target device: cuda:0\n",
            "[*] Instantiating Pretrained VLA model\n",
            "[*] Loading in BF16 with Flash-Attention Enabled\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">08/21 [20:30:49] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> | &gt;&gt; Expected `<span style=\"color: #808000; text-decoration-color: #808000\">transformers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.40</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>` and `<span style=\"color: #808000; text-decoration-color: #808000\">tokenizers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.19</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>`   <a href=\"file:///home/zijianwang/.cache/huggingface/modules/transformers_modules/openvla/openvla-7b/31f090d05236101ebfc381b61c674dd4746d4ce0/modeling_prismatic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">modeling_prismatic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/zijianwang/.cache/huggingface/modules/transformers_modules/openvla/openvla-7b/31f090d05236101ebfc381b61c674dd4746d4ce0/modeling_prismatic.py#228\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">228</span></a>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         but got `<span style=\"color: #808000; text-decoration-color: #808000\">transformers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.53</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>` and `<span style=\"color: #808000; text-decoration-color: #808000\">tokenizers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.21</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>`; there  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         might be inference-time regressions due to dependency changes.  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         If in doubt, pleaseuse the above versions.                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m08/21 [20:30:49]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m | >> Expected `\u001b[33mtransformers\u001b[0m==\u001b[1;36m4.40\u001b[0m.\u001b[1;36m1\u001b[0m` and `\u001b[33mtokenizers\u001b[0m==\u001b[1;36m0.19\u001b[0m.\u001b[1;36m1\u001b[0m`   \u001b]8;id=75954;file:///home/zijianwang/.cache/huggingface/modules/transformers_modules/openvla/openvla-7b/31f090d05236101ebfc381b61c674dd4746d4ce0/modeling_prismatic.py\u001b\\\u001b[2mmodeling_prismatic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=861168;file:///home/zijianwang/.cache/huggingface/modules/transformers_modules/openvla/openvla-7b/31f090d05236101ebfc381b61c674dd4746d4ce0/modeling_prismatic.py#228\u001b\\\u001b[2m228\u001b[0m\u001b]8;;\u001b\\\n",
              "\u001b[2;36m                 \u001b[0m         but got `\u001b[33mtransformers\u001b[0m==\u001b[1;36m4.53\u001b[0m.\u001b[1;36m3\u001b[0m` and `\u001b[33mtokenizers\u001b[0m==\u001b[1;36m0.21\u001b[0m.\u001b[1;36m2\u001b[0m`; there  \u001b[2m                         \u001b[0m\n",
              "\u001b[2;36m                 \u001b[0m         might be inference-time regressions due to dependency changes.  \u001b[2m                         \u001b[0m\n",
              "\u001b[2;36m                 \u001b[0m         If in doubt, pleaseuse the above versions.                      \u001b[2m                         \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Policy model loaded successfully\n",
            "Model device: cuda:0\n",
            "Model dtype: torch.bfloat16\n",
            "Total parameters: 7,707,479,616\n",
            "Trainable parameters: 166,242,432\n",
            "Trainable ratio: 2.16%\n",
            "\n",
            "------------------------------\n",
            "[2/2] Loading reference model...\n",
            "Target device: cuda:1\n",
            "[*] Instantiating Pretrained VLA model\n",
            "[*] Loading in BF16 with Flash-Attention Enabled\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">08/21 [20:32:09] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> | &gt;&gt; Expected `<span style=\"color: #808000; text-decoration-color: #808000\">transformers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.40</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>` and `<span style=\"color: #808000; text-decoration-color: #808000\">tokenizers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.19</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>`   <a href=\"file:///home/zijianwang/.cache/huggingface/modules/transformers_modules/openvla/openvla-7b/31f090d05236101ebfc381b61c674dd4746d4ce0/modeling_prismatic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">modeling_prismatic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/zijianwang/.cache/huggingface/modules/transformers_modules/openvla/openvla-7b/31f090d05236101ebfc381b61c674dd4746d4ce0/modeling_prismatic.py#228\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">228</span></a>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         but got `<span style=\"color: #808000; text-decoration-color: #808000\">transformers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.53</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>` and `<span style=\"color: #808000; text-decoration-color: #808000\">tokenizers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.21</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>`; there  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         might be inference-time regressions due to dependency changes.  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         If in doubt, pleaseuse the above versions.                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m08/21 [20:32:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m | >> Expected `\u001b[33mtransformers\u001b[0m==\u001b[1;36m4.40\u001b[0m.\u001b[1;36m1\u001b[0m` and `\u001b[33mtokenizers\u001b[0m==\u001b[1;36m0.19\u001b[0m.\u001b[1;36m1\u001b[0m`   \u001b]8;id=682554;file:///home/zijianwang/.cache/huggingface/modules/transformers_modules/openvla/openvla-7b/31f090d05236101ebfc381b61c674dd4746d4ce0/modeling_prismatic.py\u001b\\\u001b[2mmodeling_prismatic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=50631;file:///home/zijianwang/.cache/huggingface/modules/transformers_modules/openvla/openvla-7b/31f090d05236101ebfc381b61c674dd4746d4ce0/modeling_prismatic.py#228\u001b\\\u001b[2m228\u001b[0m\u001b]8;;\u001b\\\n",
              "\u001b[2;36m                 \u001b[0m         but got `\u001b[33mtransformers\u001b[0m==\u001b[1;36m4.53\u001b[0m.\u001b[1;36m3\u001b[0m` and `\u001b[33mtokenizers\u001b[0m==\u001b[1;36m0.21\u001b[0m.\u001b[1;36m2\u001b[0m`; there  \u001b[2m                         \u001b[0m\n",
              "\u001b[2;36m                 \u001b[0m         might be inference-time regressions due to dependency changes.  \u001b[2m                         \u001b[0m\n",
              "\u001b[2;36m                 \u001b[0m         If in doubt, pleaseuse the above versions.                      \u001b[2m                         \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 10.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Reference model loaded successfully\n",
            "Model device: cuda:1\n",
            "Model dtype: torch.bfloat16\n",
            "✓ Reference model set to eval mode and frozen\n",
            "\n",
            "==================================================\n",
            "MODEL LOADING SUMMARY\n",
            "==================================================\n",
            "Policy Model Device: cuda:0\n",
            "Reference Model Device: cuda:1\n",
            "Policy Model Trainable: 878 params\n",
            "Reference Model Trainable: 0 params\n",
            "Models loaded successfully!\n",
            "==================================================\n",
            "GPU cache cleared.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Model Loading Section\n",
        "\"\"\"\n",
        "\n",
        "print(\"Starting model loading...\")\n",
        "print(\"This may take several minutes depending on model size and device speed.\")\n",
        "print(\"\\n\" + \"-\"*30)\n",
        "\n",
        "# Load policy model with LoRA\n",
        "print(\"[1/2] Loading policy model (with LoRA)...\")\n",
        "print(f\"Target device: {model_cfg.device}\")\n",
        "\n",
        "try:\n",
        "    policy_model = setup_vla_model_with_lora(model_cfg)\n",
        "    print(f\"✓ Policy model loaded successfully\")\n",
        "    print(f\"Model device: {next(policy_model.parameters()).device}\")\n",
        "    print(f\"Model dtype: {next(policy_model.parameters()).dtype}\")\n",
        "    \n",
        "    # Count parameters\n",
        "    total_params = sum(p.numel() for p in policy_model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in policy_model.parameters() if p.requires_grad)\n",
        "    print(f\"Total parameters: {total_params:,}\")\n",
        "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "    print(f\"Trainable ratio: {100 * trainable_params / total_params:.2f}%\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"✗ Failed to load policy model: {e}\")\n",
        "    raise\n",
        "\n",
        "print(\"\\n\" + \"-\"*30)\n",
        "\n",
        "# Load reference model\n",
        "print(\"[2/2] Loading reference model...\")\n",
        "print(f\"Target device: {ref_config.device}\")\n",
        "\n",
        "try:\n",
        "    ref_model = setup_vla_model_with_lora(ref_config)\n",
        "    print(f\"✓ Reference model loaded successfully\")\n",
        "    print(f\"Model device: {next(ref_model.parameters()).device}\")\n",
        "    print(f\"Model dtype: {next(ref_model.parameters()).dtype}\")\n",
        "    \n",
        "    # Set reference model to eval mode and freeze parameters\n",
        "    ref_model.eval()\n",
        "    for param in ref_model.parameters():\n",
        "        param.requires_grad = False\n",
        "    print(\"✓ Reference model set to eval mode and frozen\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"✗ Failed to load reference model: {e}\")\n",
        "    raise\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"MODEL LOADING SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Policy Model Device: {next(policy_model.parameters()).device}\")\n",
        "print(f\"Reference Model Device: {next(ref_model.parameters()).device}\")\n",
        "print(f\"Policy Model Trainable: {sum(p.requires_grad for p in policy_model.parameters())} params\")\n",
        "print(f\"Reference Model Trainable: {sum(p.requires_grad for p in ref_model.parameters())} params\")\n",
        "print(\"Models loaded successfully!\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Optional: Clear cache to free up memory\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"GPU cache cleared.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logging to local log file: ./experiments/logs/DPO-libero_10-openvla-2025_08_21-20_30_29--notebook_demo.txt\n",
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Task suite: libero_10\n"
          ]
        }
      ],
      "source": [
        "processor, log_file, task_suite, num_tasks_in_suite, resize_size = setup_logging_and_environment(model_cfg, policy_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n"
          ]
        }
      ],
      "source": [
        "task = task_suite.get_task(model_cfg.task_num)\n",
        "env, task_description = get_libero_env(task, model_cfg.model_family, resolution=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "put both the cream cheese box and the butter in the basket\n"
          ]
        }
      ],
      "source": [
        "print(task_description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*] Setting up dataset and data loader...\n",
            "Found 212 success trajectories\n",
            "Task distribution: [('2', 21), ('6', 24), ('5', 36), ('1', 31), ('7', 24), ('0', 27), ('4', 22), ('9', 13), ('3', 9), ('8', 5)]\n",
            "Dataset created with 31 trajectory pairs\n"
          ]
        }
      ],
      "source": [
        "def setup_data_loader(cfg, processor, model, env, task_suite, resize_size):\n",
        "    \"\"\"Setup the training data loader.\"\"\"\n",
        "    print(\"[*] Setting up dataset and data loader...\")\n",
        "    \n",
        "    # Create dataset instance\n",
        "    dataset = TrajectoryDataset(\n",
        "        cfg, \n",
        "        cfg.winner_trajectory_path, \n",
        "        cfg.task_suite_name, \n",
        "        processor, \n",
        "        env, \n",
        "        task_suite,\n",
        "        device=cfg.device, \n",
        "        model=model, \n",
        "        img_size=resize_size,\n",
        "        stream_length=cfg.stream_length,\n",
        "        task_num=cfg.task_num\n",
        "    )\n",
        "    \n",
        "    # Create data collator\n",
        "    data_collator = DataCollatorForPreference(pad_token_id=processor.tokenizer.pad_token_id)\n",
        "    \n",
        "    # Create data loader\n",
        "    train_dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=cfg.batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=data_collator\n",
        "    )\n",
        "    \n",
        "    print(f\"Dataset created with {len(dataset)} trajectory pairs\")\n",
        "    return train_dataloader\n",
        "\n",
        "\n",
        "train_dataloader = setup_data_loader(model_cfg, processor, policy_model, env, task_suite, resize_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*] Verifying data loader setup...\n",
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n",
            "Batch keys: dict_keys(['prompt_input_ids', 'prompt_attention_mask', 'chosen_input_ids', 'chosen_attention_mask', 'rejected_input_ids', 'rejected_attention_mask', 'pixel_values', 'distance'])\n",
            "Chosen input shape: torch.Size([1, 80])\n",
            "Pixel values shape: torch.Size([1, 6, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "print(\"[*] Verifying data loader setup...\")\n",
        "test_batch = next(iter(train_dataloader))\n",
        "print(f\"Batch keys: {test_batch.keys()}\")\n",
        "print(f\"Chosen input shape: {test_batch['chosen_input_ids'].shape}\")\n",
        "print(f\"Pixel values shape: {test_batch['pixel_values'].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "Policy model device: cuda:0\n",
            "Reference model device: cuda:1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n",
            "batch_idx: 0, total_loss: 0.4686, dpo_loss: 0.0000, sft_loss: 4.6859, distance: tensor([0.0003], dtype=torch.float64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 1/100 [00:30<50:21, 30.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved adapter to /mnt/sda/home/zijianwang/openvla/DPO_adapter_tmp_dir/openvla-7b+libero_10_no_noops+task1+b1+lr-0.0005+lora-r48+dropout-0.0--2025-08-21_21-07-02--notebook_demo/ckpt-0, batch_idx: 0\n",
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n",
            "batch_idx: 1, total_loss: 0.4241, dpo_loss: 0.0000, sft_loss: 4.2409, distance: tensor([0.0874], dtype=torch.float64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 2/100 [00:53<42:48, 26.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n",
            "batch_idx: 2, total_loss: 0.5730, dpo_loss: 0.0000, sft_loss: 5.7303, distance: tensor([0.0887], dtype=torch.float64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 3/100 [01:17<40:29, 25.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n",
            "batch_idx: 3, total_loss: 0.4000, dpo_loss: 0.0000, sft_loss: 3.9997, distance: tensor([0.1125], dtype=torch.float64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 4/100 [01:35<35:40, 22.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n",
            "batch_idx: 4, total_loss: 10.1857, dpo_loss: 9.8125, sft_loss: 3.7316, distance: tensor([0.0323], dtype=torch.float64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 5/100 [02:01<37:26, 23.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n",
            "batch_idx: 5, total_loss: 0.3952, dpo_loss: 0.0000, sft_loss: 3.9516, distance: tensor([0.1022], dtype=torch.float64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 6/100 [02:21<35:11, 22.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n",
            "batch_idx: 6, total_loss: 0.2472, dpo_loss: 0.0000, sft_loss: 2.4720, distance: tensor([0.0262], dtype=torch.float64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 7/100 [02:37<31:18, 20.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n",
            "batch_idx: 7, total_loss: 5.0395, dpo_loss: 4.6875, sft_loss: 3.5203, distance: tensor([0.1216], dtype=torch.float64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 8/100 [02:58<31:20, 20.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n",
            "batch_idx: 8, total_loss: 0.3723, dpo_loss: 0.0000, sft_loss: 3.7234, distance: tensor([0.0973], dtype=torch.float64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 9/100 [03:23<33:05, 21.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n",
            "batch_idx: 9, total_loss: 0.3493, dpo_loss: 0.0000, sft_loss: 3.4927, distance: tensor([0.0527], dtype=torch.float64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 10/100 [03:47<33:55, 22.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n",
            "batch_idx: 10, total_loss: 0.3157, dpo_loss: 0.0000, sft_loss: 3.1571, distance: tensor([0.0704], dtype=torch.float64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 11/100 [04:06<31:49, 21.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved adapter to /mnt/sda/home/zijianwang/openvla/DPO_adapter_tmp_dir/openvla-7b+libero_10_no_noops+task1+b1+lr-0.0005+lora-r48+dropout-0.0--2025-08-21_21-07-02--notebook_demo/ckpt-10, batch_idx: 10\n",
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n",
            "batch_idx: 11, total_loss: 0.3267, dpo_loss: 0.0000, sft_loss: 3.2669, distance: tensor([0.0426], dtype=torch.float64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 12/100 [04:31<33:15, 22.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n",
            "batch_idx: 12, total_loss: 0.3372, dpo_loss: 0.0791, sft_loss: 2.5813, distance: tensor([0.1054], dtype=torch.float64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 13/100 [04:49<30:44, 21.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n",
            "batch_idx: 13, total_loss: 0.2872, dpo_loss: 0.0000, sft_loss: 2.8716, distance: tensor([0.1116], dtype=torch.float64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 14/100 [05:11<30:49, 21.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n",
            "batch_idx: 14, total_loss: 0.3194, dpo_loss: 0.0000, sft_loss: 3.1939, distance: tensor([0.0153], dtype=torch.float64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 15/100 [05:33<30:41, 21.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n",
            "batch_idx: 15, total_loss: 0.3448, dpo_loss: 0.0000, sft_loss: 3.4482, distance: tensor([0.1151], dtype=torch.float64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 16/100 [05:52<29:07, 20.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n",
            "batch_idx: 16, total_loss: 0.2774, dpo_loss: 0.0000, sft_loss: 2.7735, distance: tensor([0.0005], dtype=torch.float64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 17/100 [06:24<33:28, 24.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n",
            "batch_idx: 17, total_loss: 0.3051, dpo_loss: 0.0000, sft_loss: 3.0510, distance: tensor([0.0267], dtype=torch.float64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 18/100 [06:46<31:58, 23.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[Warning]: datasets path /mnt/sda/home/zijianwang/LIBERO/libero/libero/../datasets does not exist!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[*] Training interrupted by user\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "print(model_cfg.use_wandb)\n",
        "try:\n",
        "    final_adapter_dir = train_dpo(\n",
        "        model=policy_model, \n",
        "        ref_model=ref_model, \n",
        "        train_dataloader=train_dataloader, \n",
        "        cfg=model_cfg, \n",
        "        if_not_demo=model_cfg.use_wandb\n",
        "    )\n",
        "    \n",
        "    print(f\"[*] Training completed successfully!\")\n",
        "    print(f\"[*] Final adapter saved to: {final_adapter_dir}\")\n",
        "    \n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n[*] Training interrupted by user\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"[*] Training failed with error: {e}\")\n",
        "    raise"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "openvla",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
